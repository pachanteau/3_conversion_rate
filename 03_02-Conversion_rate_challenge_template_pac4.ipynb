{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import  OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_curve\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) # to avoid deprecation warnings\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "# setting Jedha color palette as default\n",
    "pio.templates[\"jedha\"] = go.layout.Template(\n",
    "    layout_colorway=[\"#4B9AC7\", \"#4BE8E0\", \"#9DD4F3\", \"#97FBF6\", \"#2A7FAF\", \"#23B1AB\", \"#0E3449\", \"#015955\"]\n",
    ")\n",
    "pio.templates.default = \"jedha\"\n",
    "\n",
    "pio.renderers.default = \"iframe_connected\" # to be replaced by \"iframe\" if working on JULIE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "...Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import dataset\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "dataset = pd.read_csv(\"conversion_data_train.csv\")\n",
    "print(\"...Done.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separating labels from features...\n",
      "...Done.\n",
      "\n",
      "Y : \n",
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "3    0\n",
      "4    0\n",
      "Name: converted, dtype: int64\n",
      "\n",
      "X :\n",
      "   total_pages_visited  age  new_user  country  source\n",
      "0                    2   22         1    China  Direct\n",
      "1                    3   21         1       UK     Ads\n",
      "2                   14   20         0  Germany     Seo\n",
      "3                    3   23         1       US     Seo\n",
      "4                    3   28         1       US  Direct\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Separate target variable Y from features X\n",
    "print(\"Separating labels from features...\")\n",
    "features_list = ['total_pages_visited','age','new_user','country','source']\n",
    "target_variable = \"converted\"\n",
    "\n",
    "X = dataset.loc[:,features_list]\n",
    "Y = dataset.loc[:,target_variable]\n",
    "\n",
    "print(\"...Done.\")\n",
    "print()\n",
    "\n",
    "print('Y : ')\n",
    "print(Y.head())\n",
    "print()\n",
    "print('X :')\n",
    "print(X.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284580, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "      <th>new_user</th>\n",
       "      <th>source</th>\n",
       "      <th>total_pages_visited</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284580</td>\n",
       "      <td>284580.000000</td>\n",
       "      <td>284580.000000</td>\n",
       "      <td>284580</td>\n",
       "      <td>284580.000000</td>\n",
       "      <td>284580.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Seo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>160124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>139477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>30.564203</td>\n",
       "      <td>0.685452</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.873252</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8.266789</td>\n",
       "      <td>0.464336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.341995</td>\n",
       "      <td>0.176685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country            age       new_user  source  total_pages_visited  \\\n",
       "count   284580  284580.000000  284580.000000  284580        284580.000000   \n",
       "unique       4            NaN            NaN       3                  NaN   \n",
       "top         US            NaN            NaN     Seo                  NaN   \n",
       "freq    160124            NaN            NaN  139477                  NaN   \n",
       "mean       NaN      30.564203       0.685452     NaN             4.873252   \n",
       "std        NaN       8.266789       0.464336     NaN             3.341995   \n",
       "min        NaN      17.000000       0.000000     NaN             1.000000   \n",
       "25%        NaN      24.000000       0.000000     NaN             2.000000   \n",
       "50%        NaN      30.000000       1.000000     NaN             4.000000   \n",
       "75%        NaN      36.000000       1.000000     NaN             7.000000   \n",
       "max        NaN     123.000000       1.000000     NaN            29.000000   \n",
       "\n",
       "            converted  \n",
       "count   284580.000000  \n",
       "unique            NaN  \n",
       "top               NaN  \n",
       "freq              NaN  \n",
       "mean         0.032258  \n",
       "std          0.176685  \n",
       "min          0.000000  \n",
       "25%          0.000000  \n",
       "50%          0.000000  \n",
       "75%          0.000000  \n",
       "max          1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found numeric features  ['total_pages_visited', 'age', 'new_user']  at positions  [0, 1, 2]\n",
      "Found categorical features  ['country', 'source']  at positions  [3, 4]\n",
      "Dividing into train and test sets...\n",
      "...Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Automatically detect positions of numeric/categorical features\n",
    "idx = 0\n",
    "numeric_features = []\n",
    "numeric_indices = []\n",
    "categorical_features = []\n",
    "categorical_indices = []\n",
    "for i,t in X.dtypes.iteritems():\n",
    "    if ('float' in str(t)) or ('int' in str(t)) :\n",
    "        numeric_features.append(i)\n",
    "        numeric_indices.append(idx)\n",
    "    else :\n",
    "        categorical_features.append(i)\n",
    "        categorical_indices.append(idx)\n",
    "\n",
    "    idx = idx + 1\n",
    "\n",
    "print('Found numeric features ', numeric_features,' at positions ', numeric_indices)\n",
    "print('Found categorical features ', categorical_features,' at positions ', categorical_indices)\n",
    "\n",
    "# Divide dataset Train set & Test set \n",
    "print(\"Dividing into train and test sets...\")\n",
    "# WARNING : don't forget stratify=Y for classification problems\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0, stratify = Y)\n",
    "print(\"...Done.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert pandas DataFrames to numpy arrays...\n",
      "...Done\n",
      "[[1 19 1 'China' 'Seo']\n",
      " [5 33 1 'US' 'Direct']\n",
      " [2 51 1 'US' 'Ads']\n",
      " [1 17 0 'China' 'Seo']\n",
      " [5 28 1 'China' 'Seo']]\n",
      "[[1 34 1 'UK' 'Ads']\n",
      " [5 32 0 'UK' 'Ads']]\n",
      "\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Convert pandas DataFrames to numpy arrays before using scikit-learn\n",
    "print(\"Convert pandas DataFrames to numpy arrays...\")\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "Y_train = Y_train.tolist()\n",
    "Y_test = Y_test.tolist()\n",
    "print(\"...Done\")\n",
    "\n",
    "print(X_train[0:5,:])\n",
    "print(X_test[0:2,:])\n",
    "print()\n",
    "print(Y_train[0:5])\n",
    "print(Y_test[0:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding categorical features and standardizing numerical features...\n",
      "\n",
      "[[1 19 1 'China' 'Seo']\n",
      " [5 33 1 'US' 'Direct']\n",
      " [2 51 1 'US' 'Ads']\n",
      " [1 17 0 'China' 'Seo']\n",
      " [5 28 1 'China' 'Seo']]\n",
      "...Done\n",
      "[[ 0.          0.          0.          0.          1.         -1.15935344\n",
      "  -1.3990984   0.67651656]\n",
      " [ 0.          0.          1.          1.          0.          0.03743241\n",
      "   0.29299544  0.67651656]\n",
      " [ 0.          0.          1.          0.          0.         -0.86015697\n",
      "   2.46854467  0.67651656]\n",
      " [ 0.          0.          0.          0.          1.         -1.15935344\n",
      "  -1.64082609 -1.47816042]\n",
      " [ 0.          0.          0.          0.          1.          0.03743241\n",
      "  -0.31132378  0.67651656]]\n"
     ]
    }
   ],
   "source": [
    "# Encoding categorical features and standardizing numerical features\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "print()\n",
    "print(X_train[0:5,:])\n",
    "\n",
    "# Normalization\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "# OHE / dummyfication\n",
    "categorical_transformer = OneHotEncoder(drop='first')\n",
    "\n",
    "featureencoder = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, categorical_indices),    \n",
    "        ('num', numeric_transformer, numeric_indices)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "X_train = featureencoder.fit_transform(X_train)\n",
    "print(\"...Done\")\n",
    "print(X_train[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding labels...\n",
      "[0, 0, 0, 0, 0]\n",
      "...Done\n",
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Label encoding\n",
    "print(\"Encoding labels...\")\n",
    "print(Y_train[0:5])\n",
    "encoder = LabelEncoder()\n",
    "Y_train = encoder.fit_transform(Y_train)\n",
    "print(\"...Done\")\n",
    "print(Y_train[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model...\n",
      "...Done.\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "print(\"Train model...\")\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, Y_train)\n",
    "print(\"...Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on training set...\n",
      "...Done.\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predictions on training set\n",
    "print(\"Predictions on training set...\")\n",
    "Y_train_pred = classifier.predict(X_train)\n",
    "print(\"...Done.\")\n",
    "print(Y_train_pred)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing missing values...\n",
      "[[1 34 1 'UK' 'Ads']\n",
      " [5 32 0 'UK' 'Ads']\n",
      " [1 44 1 'US' 'Ads']\n",
      " [1 35 1 'US' 'Direct']\n",
      " [3 29 1 'US' 'Direct']]\n",
      "Encoding categorical features and standardizing numerical features...\n",
      "[[1 34 1 'UK' 'Ads']\n",
      " [5 32 0 'UK' 'Ads']\n",
      " [1 44 1 'US' 'Ads']\n",
      " [1 35 1 'US' 'Direct']\n",
      " [3 29 1 'US' 'Direct']]\n",
      "...Done\n",
      "[[ 0.          1.          0.          0.          0.         -1.15935344\n",
      "   0.41385929  0.67651656]\n",
      " [ 0.          1.          0.          0.          0.          0.03743241\n",
      "   0.1721316  -1.47816042]\n",
      " [ 0.          0.          1.          0.          0.         -1.15935344\n",
      "   1.62249775  0.67651656]\n",
      " [ 0.          0.          1.          1.          0.         -1.15935344\n",
      "   0.53472314  0.67651656]\n",
      " [ 0.          0.          1.          1.          0.         -0.56096051\n",
      "  -0.19045994  0.67651656]]\n",
      "Encoding labels...\n",
      "[0, 0, 0, 0, 0]\n",
      "...Done\n",
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Missing values\n",
    "\n",
    "print(\"Imputing missing values...\")\n",
    "print(X_test[0:5,:])\n",
    "\n",
    "# Encoding categorical features and standardizing numerical features\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "print(X_test[0:5,:])\n",
    "\n",
    "\n",
    "X_test = featureencoder.transform(X_test)\n",
    "print(\"...Done\")\n",
    "print(X_test[0:5,:])\n",
    "\n",
    "\n",
    "# Label encoding\n",
    "print(\"Encoding labels...\")\n",
    "print(Y_test[0:5])\n",
    "Y_test = encoder.transform(Y_test)\n",
    "print(\"...Done\")\n",
    "print(Y_test[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on test set...\n",
      "...Done.\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n",
      "accuracy on training set :  0.9863351254480287\n",
      "accuracy on test set :  0.9857685009487666\n",
      "\n",
      "f1-score on training set :  0.765543748586932\n",
      "f1-score on test set :  0.7554347826086957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Predictions on test set\n",
    "print(\"Predictions on test set...\")\n",
    "Y_test_pred = classifier.predict(X_test)\n",
    "print(\"...Done.\")\n",
    "print(Y_test_pred)\n",
    "print()\n",
    "\n",
    "# Print scores\n",
    "print(\"accuracy on training set : \", accuracy_score(Y_train, Y_train_pred))\n",
    "print(\"accuracy on test set : \", accuracy_score(Y_test, Y_test_pred))\n",
    "print()\n",
    "\n",
    "print(\"f1-score on training set : \", f1_score(Y_train, Y_train_pred))\n",
    "print(\"f1-score on test set : \", f1_score(Y_test, Y_test_pred))\n",
    "print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.append(X_train,X_test,axis=0)\n",
    "Y = np.append(Y_train,Y_test)\n",
    "\n",
    "classifier.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction set (without labels) : (31620, 5)\n",
      "Convert pandas DataFrames to numpy arrays...\n",
      "...Done\n",
      "[[16 28 0 'UK' 'Seo']\n",
      " [5 22 1 'UK' 'Direct']\n",
      " [1 32 1 'China' 'Seo']\n",
      " [6 32 1 'US' 'Ads']\n",
      " [3 25 0 'China' 'Seo']]\n"
     ]
    }
   ],
   "source": [
    "# Read data without labels\n",
    "data_without_labels = pd.read_csv('conversion_data_test.csv')\n",
    "print('Prediction set (without labels) :', data_without_labels.shape)\n",
    "\n",
    "# Warning : check consistency of features_list (must be the same than the features \n",
    "# used by your best classifier)\n",
    "features_list = ['total_pages_visited','age','new_user','country','source']\n",
    "X_without_labels = data_without_labels.loc[:, features_list]\n",
    "\n",
    "# Convert pandas DataFrames to numpy arrays before using scikit-learn\n",
    "print(\"Convert pandas DataFrames to numpy arrays...\")\n",
    "X_without_labels = X_without_labels.values\n",
    "print(\"...Done\")\n",
    "\n",
    "print(X_without_labels[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding categorical features and standardizing numerical features...\n",
      "...Done\n",
      "[[ 0.          1.          0.          0.          1.          3.3285935\n",
      "  -0.31132378 -1.47816042]\n",
      " [ 0.          1.          0.          1.          0.          0.03743241\n",
      "  -1.03650686  0.67651656]\n",
      " [ 0.          0.          0.          0.          1.         -1.15935344\n",
      "   0.1721316   0.67651656]\n",
      " [ 0.          0.          1.          0.          0.          0.33662888\n",
      "   0.1721316   0.67651656]\n",
      " [ 0.          0.          0.          0.          1.         -0.56096051\n",
      "  -0.67391532 -1.47816042]]\n"
     ]
    }
   ],
   "source": [
    "# WARNING : PUT HERE THE SAME PREPROCESSING AS FOR YOUR TEST SET\n",
    "# CHECK YOU ARE USING X_without_labels\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "\n",
    "X_without_labels = featureencoder.transform(X_without_labels)\n",
    "print(\"...Done\")\n",
    "print(X_without_labels[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions and dump to file\n",
    "# WARNING : MAKE SURE THE FILE IS A CSV WITH ONE COLUMN NAMED 'converted' AND NO INDEX !\n",
    "# WARNING : FILE NAME MUST HAVE FORMAT 'conversion_data_test_predictions_[name].csv'\n",
    "# where [name] is the name of your team/model separated by a '-'\n",
    "# For example : [name] = AURELIE-model1\n",
    "data = {\n",
    "    'converted': classifier.predict(X_without_labels)\n",
    "}\n",
    "\n",
    "Y_predictions = pd.DataFrame(columns=['converted'],data=data)\n",
    "Y_predictions.to_csv('conversion_data_test_predictions_PA_model_4.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
